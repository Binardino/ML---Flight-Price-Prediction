{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split,  cross_validate, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr, kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_dataset.csv', index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Feature presentation\n",
    "\n",
    "1) Airline: The name of the airline company is stored in the airline column. It is a categorical feature having 6 different airlines. \n",
    "\n",
    "2) Flight: Flight stores information regarding the plane's flight code. It is a categorical feature. \n",
    "\n",
    "3) Source City: City from which the flight takes off. It is a categorical feature having 6 unique cities. \n",
    "\n",
    "4) Departure Time: This is a derived categorical feature obtained created by grouping time periods into bins. It stores information about the departure time and have 6 unique time labels.\n",
    "\n",
    "5) Stops: A categorical feature with 3 distinct values that stores the number of stops between the source and destination cities. \n",
    "\n",
    "6) Arrival Time: This is a derived categorical feature created by grouping time intervals into bins. It has six distinct time labels and keeps information about the arrival time. \n",
    "\n",
    "7) Destination City: City where the flight will land. It is a categorical feature having 6 unique cities. \n",
    "\n",
    "8) Class: A categorical feature that contains information on seat class; it has two distinct values: Business and Economy. \n",
    "\n",
    "9) Duration: A continuous feature that displays the overall amount of time it takes to travel between cities in hours. \n",
    "\n",
    "10) Days Left: This is a derived characteristic that is calculated by subtracting the trip date by the booking date. \n",
    "\n",
    "11) Price: Target variable stores information of the ticket price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_col = ['duration', 'days_left', 'price']\n",
    "discrete_col   = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']\n",
    "\n",
    "def univariate_discrete_analysis(df, discrete_col):\n",
    "    for col in discrete_col:\n",
    "        print(f'### analysing column : {col} ###')\n",
    "        count = df[col].value_counts()\n",
    "        display(count)\n",
    "\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.countplot(data=df, x=col, order=count.index)\n",
    "\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def univariate_continuous_analysis(df, continuous_col):\n",
    "    for col in continuous_col:\n",
    "        print(f'### analysing column : {col} ###')\n",
    "        stats = df[col].describe()\n",
    "        variance = df[col].var()\n",
    "\n",
    "        display(stats)\n",
    "        print(f'Variance: {variance:.2f}')\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        #histogram\n",
    "        sns.histplot(df[col], kde=True, ax=axes[0])\n",
    "        axes[0].set_title(f'Histogram of {col}')\n",
    "        \n",
    "        #boxplot\n",
    "        sns.boxplot(x=df[col], ax=axes[1])\n",
    "        axes[1].set_title(f'Boxplot of {col}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "univariate_discrete_analysis(df=df, discrete_col=discrete_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_continuous_analysis(df=df, continuous_col=continuous_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Multivariate analysis\n",
    "\n",
    "Need to do 3 levels of multivariate analysis :\n",
    "- continuous  ↔ continuous\n",
    "- discrete    ↔ continuous\n",
    "- discrete    ↔ discrete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "for continuous columns, need to check both Pearson (linear relations) & Spearman (monotone relations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson  = df[continuous_col].corr(method='pearson')\n",
    "corr_spearman = df[continuous_col].corr(method='spearman')\n",
    "\n",
    "print('Pearson correlations')\n",
    "display(corr_pearson)\n",
    "sns.heatmap(corr_pearson, annot=True, cmap='coolwarm')\n",
    "plt.title('Pearson Correlation (Numerical)')\n",
    "plt.show()\n",
    "\n",
    "print('Spearman correlations')\n",
    "display(corr_spearman)\n",
    "\n",
    "sns.heatmap(corr_spearman, annot=True, cmap='coolwarm')\n",
    "plt.title('Spearman Correlation (Numerical)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Let's check the relation between each variable and the final flight price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "##### 1. Duration VS. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Question : Are longer flight (in duration) associated to more expensive price  ?\n",
    "\n",
    "Testing linear correlation between :\n",
    "\n",
    "duration (continuous variable)\n",
    "price (continuous variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation between flight duration & price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x=\"duration\", y=\"price\", alpha=0.3)\n",
    "sns.regplot(\n",
    "    data=df,\n",
    "    x=\"duration\",\n",
    "    y=\"price\",\n",
    "    scatter=False,\n",
    "    color=\"red\"\n",
    ")\n",
    "plt.title(\"Relation between flight duration and price\")\n",
    "plt.xlabel(\"Flight duration (hours)\")\n",
    "plt.ylabel(\"Price (Rupees)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration_bin\"] = pd.cut(\n",
    "    df[\"duration\"],\n",
    "    bins=[0, 5, 10, 20, 40, 60]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"duration_bin\",\n",
    "    y=\"price\"\n",
    ")\n",
    "plt.title(\"Price distribution by flight duration bins\")\n",
    "plt.xlabel(\"Flight duration (hours)\")\n",
    "plt.ylabel(\"Price (Rupees)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "<b>Hypothesis</b> : \n",
    "\n",
    "HO : the linear correlation between duration & price is null.\n",
    "\n",
    "H1 : the linear correlation between duration & price is significative and not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical correlation test between duration & price\n",
    "corr_duration_price, p_value_duration_price = spearmanr(df[\"duration\"], df[\"price\"])\n",
    "\n",
    "alpha = 0.02\n",
    "\n",
    "print(\"Correaltion (duration, price) :\", corr_duration_price)\n",
    "print(\"p-value :\", p_value_duration_price)\n",
    "\n",
    "if p_value_duration_price < alpha:\n",
    "    print(f\"p-value < {alpha} : we can reject H0.\")\n",
    "    print(\"Conclusion : There is a significative linear correlation between the flight duration and the flight price.\")\n",
    "else:\n",
    "    print(f\"p-value ≥ {alpha} : we cannot reject H0.\")\n",
    "    print(\"Conclusion : There is no clear significative linear correlation between the flight duration and the flight price.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### 2. Air supplier VS. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation between air supplier and price\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, x='airline', y='price')\n",
    "plt.title('Relation between airline & price')\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('price (in Roupies)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### 3. Amount of stops VS. Price\n",
    "\n",
    "Does the flight price fluctuate depending the amount of stops ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check basic distribution of stops\n",
    "df.groupby(\"stops\")[\"price\"].agg([\"median\", \"mean\", \"count\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation between amount of stops & price\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df, x='stops', y='price')\n",
    "plt.title('Relation between Amount of stops & the Flight price')\n",
    "plt.xlabel('Amount of stops')\n",
    "plt.ylabel('Price in Roupies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "<b>Hypothesis</b> : \n",
    "\n",
    "HO - no correlation between stops & price - the average price is the same regardless of the amount of stops\n",
    "\n",
    "H1 - the average price does vary depending on the amount of stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_unique = sorted(df['stops'].unique())\n",
    "print('amount of stops : ', stops_unique)\n",
    "\n",
    "groups_price_by_stops = [df[df['stops'] ==stop]['price'].values for stop in stops_unique]\n",
    "\n",
    "print(groups_price_by_stops)\n",
    "\n",
    "#stat test\n",
    "#ANOVA not relevant because unenven group sizes & uneven variance. \n",
    "#Price is very right-skewed \n",
    "\n",
    "#Kruskal–Wallis does test between groups without need to normalise\n",
    "h_stat_stop, p_value_stop = kruskal(*groups_price_by_stops)\n",
    "\n",
    "print('H stat (stop VS. price) :', h_stat_stop)\n",
    "print('p-value stop) :', p_value_stop)\n",
    "\n",
    "if p_value_stop < alpha:\n",
    "    print(f\"p-value < {alpha} : we can reject H0.\")\n",
    "    print(\"Conclusion : There is a significative correlation between the amount of stops and the flight price. Flight price does vary depending on the amount of stops\")\n",
    "else:\n",
    "    print(f\"p-value ≥ {alpha} : we cannot reject H0.\")\n",
    "    print(\"Conclusion : There is no clear significative correlation between the amount of stops and the flight price.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop is an ordinal discrete variable\n",
    "# #let's add to the previous statistical test another check : is there a monotonous correlation between stops & price ?\n",
    "df['stop_num'] = df['stops'].map({'zero': 0, 'one': 1, 'two_or_more':2}) \n",
    "\n",
    "spearman_corr, p_value_spearman_stop = spearmanr(df['stop_num'], df['price'])\n",
    "\n",
    "print(f\"Spearman corr: {spearman_corr:.3f}\")\n",
    "print(f\"p_value_spearman_stop: {p_value_spearman_stop:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Medians do decrease between 0 and 2 stops - there is a significative negative monotonous relation validated by Spearman test.\n",
    "Stops variable does have a significative impact on the price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### 4. Amount of Booking Lead time in days before the flight\n",
    "\n",
    "Does booking in advance lead to cheaper flight price ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_left'].unique()\n",
    "\n",
    "df['days_bin'] = pd.cut(df['days_left'], bins = [0, 5, 10, 20, 40, 60])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(data=df, x='days_bin', y='price')\n",
    "plt.title('Flight price distribution in Days bins')\n",
    "plt.xlabel('Bins of days in advance')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"days_bin\")[\"price\"].agg([\"median\", \"mean\", \"count\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The average and median price do seem to significatively decrease the higher the amount of days in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_left'].unique()\n",
    "\n",
    "df['days_bin'] = pd.cut(df['days_left'], bins = [0, 5, 10, 20, 40, 60])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(data=df, x='days_bin', y='price')\n",
    "plt.title('Flight price distribution in Days bins')\n",
    "plt.xlabel('Bins of days in advance')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "<b>Hypothesis</b> : \n",
    "\n",
    "HO : There is no significative correlation between the amount of booking lead time in days and the flight price\n",
    "\n",
    "H1 : There is a significative linear correlation between the amount of booking lead time in days and the flight price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_days_price, p_value_days_price = spearmanr(df['days_left'], df['price'])\n",
    "\n",
    "print(f\"Spearman correlation (days_left, price):{corr_days_price:.3f}\")\n",
    "print(f\"p-value booking days in advance: {p_value_days_price:.5e}\")\n",
    "\n",
    "if p_value_days_price < alpha:\n",
    "    print(f\"p-value < {alpha} : we can reject H0.\")\n",
    "    print(\"Conclusion : There is a significative correlation between the amount of booking lead time in days and the flight price. Flight price does vary depending on the amount of booked days in advance\")\n",
    "else:\n",
    "    print(f\"p-value ≥ {alpha} : we cannot reject H0.\")\n",
    "    print(\"Conclusion : There is no clear significative correlation between the amount of booking lead time in days and the flight price.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NaN per columns')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping classes\n",
    "print(df['class'].unique())\n",
    "\n",
    "df['class_num'] = df['class'].map({'Economy': 0, 'Business': 1})\n",
    "\n",
    "print(df['class_num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['flight'].unique())\n",
    "\n",
    "print('-' * 30)\n",
    "print('high cardinality and not informative')\n",
    "print('-' * 30)\n",
    "\n",
    "print(df[\"flight\"].value_counts().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "flight_encoded = le.fit_transform(df['flight'])\n",
    "mi_flight = mutual_info_regression(flight_encoded.reshape(-1, 1),\n",
    "                                    df['price'],\n",
    "                                    random_state=42\n",
    "                                    )\n",
    "\n",
    "print(('MI(flight-> price): ', mi_flight[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "\"Flight\" column has a very high Mutual Info Regression ; it is due to its very high cardinality, which pollutes results\n",
    "\n",
    "\"Flight\" column is a simple flight identifier with no additional info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flight'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing MI to other features\n",
    "features = [\"airline\", \"class\", \"duration\" , \"stops\", \"days_left\", \"flight\"]\n",
    "\n",
    "X = df[features].apply(lambda col: col.astype(\"category\").cat.codes)\n",
    "y = df[\"price\"]\n",
    "\n",
    "mi = mutual_info_regression(X, y, random_state=42)\n",
    "\n",
    "pd.Series(mi, index=features).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Preparing ML Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping df back up\n",
    "df_raw = df.copy()\n",
    "\n",
    "# Flight column is useless\n",
    "df.drop(columns='flight', inplace=True)\n",
    "\n",
    "#dropping legacy categorical & bins non encoded columns\n",
    "#del bin columns used for graph\n",
    "df.drop(columns=['duration_bin', 'days_bin'], inplace=True)\n",
    "\n",
    "#del manual encoding to do proper SKLearn encoding\n",
    "df.drop(columns=['stops', 'class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='price')\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train), X_train.shape)\n",
    "print(type(X_test), X_test.shape)\n",
    "print(type(y_train), y_train.shape)\n",
    "print(type(y_test), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting numeric & cat features\n",
    "numeric_features     = [\"duration\", \"days_left\", \"stop_num\", \"class_num\"]\n",
    "categorical_features = [\"airline\", \"source_city\", \"departure_time\", \"arrival_time\", \"destination_city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "                            steps=[\n",
    "                                ('imputer', SimpleImputer(strategy='median')), #skewed data, using median\n",
    "                                ('scaler', StandardScaler())\n",
    "                                      ]\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "                                steps=[\n",
    "                                ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "                                ('OneHot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),\n",
    "                                                ('cat', categorical_transformer , categorical_features)\n",
    "                                                ],\n",
    "                                                remainder='drop')\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit / transform\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "X_train_proc = preprocessor.transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_proc.shape, X_test_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating evaluating function to eval model results\n",
    "\n",
    "def evaluate_model(\n",
    "        name, \n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        results_dict,\n",
    "        cross_validator=5):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model using a strict experimental protocol.\n",
    "    Then refit on the entire train & evaluate it once on test.\n",
    "\n",
    "    Steps:\n",
    "    1. Cross-validation on training set (performance + stability)\n",
    "    2. Refit model on full training data\n",
    "    3. Final evaluation on the test set\n",
    "    4. Store results for later comparison\n",
    "\n",
    "    Args:\n",
    "        name (str)                      : model name\n",
    "        model (estimator | Pipeline)    : Scikit-learn Model or Pipeline\n",
    "        X_train , y_train (array)       : training data\n",
    "        X_test, y_test (array)          : test data\n",
    "        result_dict (dict)              : stocking results dict\n",
    "        cross_validator (int, optional) : Amount of folds for cross validation. Defaults to 5.\n",
    "    \"\"\"\n",
    "    \n",
    "    #step 1 - cross validation on train only\n",
    "    cv_results = cross_validate(\n",
    "        estimator=model,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=KFold(n_splits=cross_validator, shuffle=True, random_state=42),\n",
    "        scoring={\n",
    "            'mae'  : 'neg_mean_absolute_error',\n",
    "            'rmse' : 'neg_root_mean_squared_error',\n",
    "            'r2'   : 'r2'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #computing absolute average - convert negative metrics back to positive values\n",
    "    cv_mae_mean = abs(cv_results['test_mae'].mean())\n",
    "    cv_mae_std  = abs(cv_results['test_mae'].std())\n",
    "\n",
    "    cv_rmse_mean = abs(cv_results['test_rmse'].mean())\n",
    "    cv_rmse_std  = abs(cv_results['test_rmse'].std())\n",
    "    \n",
    "    cv_r2_mean = cv_results['test_r2'].mean()\n",
    "    cv_r2_std  = cv_results['test_r2'].std()\n",
    "\n",
    "    print(f'-' * 30)\n",
    "    print(f'{name}')\n",
    "    print(f'-' * 30)\n",
    "\n",
    "    print(f'cross validation ({cross_validator}-fold) on train:')\n",
    "    print(f\"  MAE  (mean ± std) : {cv_mae_mean:.2f} ± {cv_mae_std:.2f}\")\n",
    "    print(f\"  RMSE (mean ± std) : {cv_rmse_mean:.2f} ± {cv_rmse_std:.2f}\")\n",
    "    print(f\"  R²   (mean ± std) : {cv_r2_mean:.4f} ± {cv_r2_std:.4f}\")\n",
    "\n",
    "    #step 2 - refit back on full train set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #step 3 - final evaluation on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    test_mae  = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2   = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Final evaluation on test :\")\n",
    "    print(f\"  Test MAE  : {test_mae:.2f}\")\n",
    "    print(f\"  Test RMSE : {test_rmse:.2f}\")\n",
    "    print(f\"  Test R²   : {test_r2:.4f}\")\n",
    "    \n",
    "    results_dict[name] = {\n",
    "        'cv_mae_mean'  : cv_mae_mean,\n",
    "        'cv_mae_std'   : cv_mae_std,\n",
    "        'cv_rmse_mean' : cv_rmse_mean,\n",
    "        'cv_rmse_std'  : cv_rmse_std,\n",
    "        \"cv_r2_mean\"   : cv_r2_mean,\n",
    "        \"cv_r2_std\"    : cv_r2_std,\n",
    "        \"test_mae\"     : test_mae,\n",
    "        \"test_rmse\"    : test_rmse,\n",
    "        \"test_r2\"      : test_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating dict result\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# 1. Testing on Baseline DummyRegressor\n",
    "\n",
    "before training on real ML models, let's test on naive baseline.\n",
    "\n",
    "This model :\n",
    "- does not test any features\n",
    "- is a baseline. Any ML model must outperfom this bais DummyRegressor\n",
    "\n",
    "else it is a uselse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "evaluate_model(name='DummyRegressor (mean)',\n",
    "               model=dummy_model,\n",
    "               X_train=X_train,\n",
    "               y_train=y_train,\n",
    "               X_test=X_test,\n",
    "               y_test=y_test,\n",
    "               results_dict=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "# 2. LinearRgression Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_model = Pipeline(steps=[\n",
    "                                 ('preprocessor', preprocessor),\n",
    "                                 ('Linear Regression', LinearRegression())\n",
    "                                 ])\n",
    "\n",
    "evaluate_model(name='LinearRegression',\n",
    "               model=linear_reg_model,\n",
    "               X_train=X_train,\n",
    "               y_train=y_train,\n",
    "               X_test=X_test,\n",
    "               y_test=y_test,\n",
    "               results_dict=results,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "3. LinearRegression with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for a in alphas:\n",
    "    ridge_pipeline = Pipeline(steps=[\n",
    "                                    ('preprocessor', preprocessor),\n",
    "                                    ('RidgeRegression', Ridge(alpha=a))\n",
    "                                ])\n",
    "    \n",
    "    evaluate_model(name=f'Ridge Regression (alpha={a})',\n",
    "                   model=ridge_pipeline,\n",
    "                   X_train=X_train,\n",
    "                   y_train=y_train,\n",
    "                   X_test=X_test,\n",
    "                   y_test=y_test,\n",
    "                   results_dict=results,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "4. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('RandomForest', RandomForestRegressor(n_estimators=200,\n",
    "                                                               max_depth=None,\n",
    "                                                               min_samples_leaf=1,\n",
    "                                                               random_state=42,\n",
    "                                                               n_jobs=-1 #use all CPUs\n",
    "\n",
    "                        ))\n",
    "                    ])\n",
    "\n",
    "evaluate_model(model=rf_pipeline,\n",
    "               name='RandomForestRegressor',\n",
    "               X_train=X_train,\n",
    "               y_train=y_train,\n",
    "               X_test=X_test,\n",
    "               y_test=y_test,\n",
    "               results_dict=results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flight-price-ml)",
   "language": "python",
   "name": "flight-price-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
